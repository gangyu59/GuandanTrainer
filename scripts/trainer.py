import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from .simple_mlp import SimpleMLP


def train_model(X, y, epochs=50, status=None, log_callback=None):
    print(f"ðŸ”§ è®­ç»ƒæ¨¡åž‹è¾“å…¥æ£€æŸ¥: X.shape={X.shape}, y.shape={y.shape}")

    model = SimpleMLP(input_dim=X.shape[1], output_dim=y.shape[1])
    criterion = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    X_tensor = torch.from_numpy(X).float()
    y_tensor = torch.from_numpy(y).float()

    # âœ… åˆå§‹åŒ– action åˆ†å¸ƒç»Ÿè®¡
    action_counter = np.zeros(y.shape[1], dtype=np.float32)
    total_correct = 0
    total_samples = 0
    entropies = []

    for epoch in range(epochs):
        outputs = model(X_tensor)
        loss = criterion(outputs, y_tensor)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if status is not None:
            status["epoch"] = epoch + 1

        log_line = f"ðŸ“‰ Epoch {epoch + 1}/{epochs} - Loss: {loss.item():.4f}"
        print(log_line)

        if log_callback:
            log_callback(log_line)

        # âœ… é™„åŠ æŒ‡æ ‡ç»Ÿè®¡ï¼ˆæ¯è½®ï¼‰
        probs = outputs.detach().numpy()
        labels = y_tensor.numpy()

        # action åˆ†å¸ƒï¼ˆå–æ¯è¡Œæœ€å¤§å€¼å¯¹åº”ç´¢å¼•ä½œä¸ºé€‰æ‹©åŠ¨ä½œï¼‰
        preds = np.argmax(probs, axis=1)
        truths = np.argmax(labels, axis=1)
        for p in preds:
            action_counter[p] += 1

        # ç­–ç•¥ç†µï¼ˆæ¯ä¸ªæ ·æœ¬çš„åˆ†å¸ƒç†µï¼Œå–å¹³å‡ï¼‰
        entropy_batch = -np.sum(probs * np.log(probs + 1e-8), axis=1)
        entropies.append(np.mean(entropy_batch))

        # å‡†ç¡®çŽ‡
        total_correct += np.sum(preds == truths)
        total_samples += len(preds)

    # âœ… è®­ç»ƒå®ŒæˆåŽæ›´æ–° status["metrics"]
    if status is not None:
        status.update({
            "metrics": {
                "samples": len(X),
                "winrate": status.get("metrics", {}).get("winrate", 0),
                "action_dist": {int(k): float(v) for k, v in enumerate(action_counter) if v > 0},
                "accuracy": round(total_correct / total_samples, 4),
                "entropy": round(np.mean(entropies), 4),
            }
        })
